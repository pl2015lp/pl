завдання1
import urllib
from urllib import urlopen
def Clean (url):
    raw = urlopen(url).read()
    raw_contents = nltk.clean_html(raw)
    tokens = nltk.word_tokenize(raw_contents)
    return tokens
url = "http://www.gutenberg.org/files/1342/1342.txt"
s = Clean(url) 
print s[1000:1060]

завдання2
def load(f):
	func=open(f)
	raw=func.read()
	return raw

print load ('C:\Python27\corpus.txt')

завдання3
sent = ['The', 'dog', 'gave', 'John', 'the','newspaper']
result = [(w, len(w)) for w in sent]
print result

завдання 4
a="3"*7
print 'a=', a
b=3*7
print 'b=', b
c=int("3")*7
print 'c=', c
d=str(3)*7
print 'd=', d
print 'a==b', a==b
print 'a==c', a==c
print 'a==d', a==d
print 'b==c', b==c
print 'b==d', b==d
print 'c==d', c==d
print "a=d i b=c"

завдання 5
print '%6s' % 'tale'
print '%-6s' % 'tale'
print '%6s' % 'interesting'
print '%-6s' % 'interesting'
print 'Yakshcho strichka maie bilshe nizh 6 symvoliv, to vyrivniuvannia ne vidbuvaietsia'

завдання 7
f = open('C:\Python27\wfreq.txt').readlines()
print f
a=[]
for i in f:
        b=i.split()
        a.append([b[0],int(b[1])])
print a

завдання 9
from__future__ import division
import nltk, re, pprint
import collections
f='Minden emberi leny szabadon szuletik es egyenlo joga van'
a=f.split()
s=set()
for word in a:
	vowels=[]
	for char in word:
		if char in 'ayoiei':
			vowels.append(char)
			s.add(''.join(vowels))
print sorted(s)
p=nltk.bigrams(s)
print p
freq = collections.Counter(s)
print freq

завдання 13
import nltk
from nltk.corpus import gutenberg
from nltk.probability import FreqDist
raw = open('austen-emma.txt').read()
tokens = nltk.word_tokenize(raw)
porter = nltk.PorterStemmer()
lancaster = nltk.LancasterStemmer()
print ([porter.stem(t) for t in tokens][:50], '\n')
print ([lancaster.stem(t) for t in tokens][:50])


завдання 14
from __future__ import division
import nltk, re, pprint
from nltk.corpus impost abc
l=0
n=0
for w in nltk.corpus.abc.words():
	l+=len(w)
	n+=1
m1=1/n
print m1
m2=len(nltk.corpus.abc.words())/len(nltk.corpus.abc.sents())
print m2
ari=4.71*m1+0.5*m2-21.43
print ari
sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')
text=nltk.corpus.abc.raw('rural.txt')
sents=sent_tokenizer.tokenize(text)
pprint.pprint(sents[1:5])
text=nltk.corpus.abc.raw('science.txt')
sents=sent_tokenizer.tokenize(text)
pprint.pprint(sents[1:5])